{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b259f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Posture classification & evaluation for data_new/\n",
    "\n",
    "â€¢ éæ­· data_new/p1~p5\n",
    "â€¢ MediaPipe Pose æ¨è«–ï¼Œè¨ˆç®— score â†’ label\n",
    "â€¢ æ··æ·†çŸ©é™£ã€precision/recall/F1\n",
    "â€¢ è¨˜éŒ„ç„¡æ³•åµæ¸¬éª¨æ¶ / è®€æª”å¤±æ•—çš„åœ–ç‰‡\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d82ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- åˆ†é¡è¦å‰‡ ----------\n",
    "def score_to_label(score: int) -> str:\n",
    "    if score in (10, 7):\n",
    "        return \"p1\"\n",
    "    if score == 5:\n",
    "        return \"p2\"\n",
    "    if score == 4:\n",
    "        return \"p3\"\n",
    "    if score == 2:\n",
    "        return \"p4\"\n",
    "    if score == 1:\n",
    "        return \"p5\"\n",
    "    return \"unknown\"\n",
    "\n",
    "# ---------- å§¿å‹¢è§’ã€å¾—åˆ† ----------\n",
    "def angle_between(v1, v2):\n",
    "    v1, v2 = np.array(v1), np.array(v2)\n",
    "    cosang = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    return np.degrees(np.arccos(np.clip(cosang, -1.0, 1.0)))\n",
    "\n",
    "def get_posture_score(theta_raise, theta_elbow):\n",
    "    if theta_raise >= 170:\n",
    "        return 10\n",
    "    if 100 < theta_raise < 170:\n",
    "        return 7\n",
    "    if 80 <= theta_raise <= 100:\n",
    "        return 5 if theta_elbow >= 150 else 4\n",
    "    if 50 <= theta_raise < 80:\n",
    "        return 2\n",
    "    if theta_raise < 50:\n",
    "        return 1\n",
    "    return 0  # æœªå®šç¾©\n",
    "\n",
    "def arm_score(lm, side, mp_pose):\n",
    "    SH = lm[getattr(mp_pose.PoseLandmark, f\"{side}_SHOULDER\").value]\n",
    "    EL = lm[getattr(mp_pose.PoseLandmark, f\"{side}_ELBOW\").value]\n",
    "    WR = lm[getattr(mp_pose.PoseLandmark, f\"{side}_WRIST\").value]\n",
    "    HIP = lm[getattr(mp_pose.PoseLandmark, f\"{side}_HIP\").value]\n",
    "\n",
    "    SH = [SH.x, SH.y, SH.z]\n",
    "    EL = [EL.x, EL.y, EL.z]\n",
    "    WR = [WR.x, WR.y, WR.z]\n",
    "    HIP = [HIP.x, HIP.y, HIP.z]\n",
    "\n",
    "    theta_raise = angle_between(np.array(EL) - SH, np.array(HIP) - SH)\n",
    "    theta_elbow = angle_between(np.array(WR) - EL, np.array(SH) - EL)\n",
    "\n",
    "    return get_posture_score(theta_raise, theta_elbow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd7e9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- è³‡æ–™å¤¾ ----------\n",
    "DATA_NEW = Path(\"../../data_new\")\n",
    "POSE_CLASSES = [\"p1\", \"p2\", \"p3\", \"p4\", \"p5\"]\n",
    "\n",
    "true_labels, pred_labels = [], []\n",
    "undetected_images, read_failed_images = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd70be7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing p1:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing p1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:27<00:00,  1.48s/it]\n",
      "Processing p2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.40s/it]\n",
      "Processing p3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [01:02<00:00,  1.49s/it]\n",
      "Processing p4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 638/638 [15:26<00:00,  1.45s/it]\n",
      "Processing p5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:00<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š æ··æ·†çŸ©é™£ (é †åº p1~p5):\n",
      "[[ 20  26  20   3   2]\n",
      " [  0   1   0   0   0]\n",
      " [  5   8  19   2   0]\n",
      " [ 14  46 194 166 135]\n",
      " [  1   2  15  25  29]]\n",
      "\n",
      "ğŸ“ˆ åˆ†é¡å ±å‘Š:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          p1      0.500     0.282     0.360        71\n",
      "          p2      0.012     1.000     0.024         1\n",
      "          p3      0.077     0.559     0.135        34\n",
      "          p4      0.847     0.299     0.442       555\n",
      "          p5      0.175     0.403     0.244        72\n",
      "\n",
      "    accuracy                          0.321       733\n",
      "   macro avg      0.322     0.508     0.241       733\n",
      "weighted avg      0.710     0.321     0.400       733\n",
      "\n",
      "\n",
      "âš ï¸  å…± 128 å¼µåœ–ç‰‡æœªç´å…¥è©•ä¼°ï¼Œæ¸…å–®å·²å¯«å…¥ undetected_images.txt\n",
      "  - cv2 è®€å–å¤±æ•—ï¼š1 å¼µ\n",
      "  - Pose æœªåµæ¸¬åˆ°äººé«”ï¼š127 å¼µ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------- MediaPipe ----------\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=True, model_complexity=2)\n",
    "\n",
    "for cls in POSE_CLASSES:\n",
    "    for img_path in tqdm(sorted((DATA_NEW/cls).glob(\"*\")), desc=f\"Processing {cls}\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            read_failed_images.append(img_path.relative_to(DATA_NEW).as_posix())\n",
    "            continue\n",
    "\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(img_rgb)\n",
    "\n",
    "        if not results.pose_landmarks:\n",
    "            undetected_images.append(img_path.relative_to(DATA_NEW).as_posix())\n",
    "            continue\n",
    "\n",
    "        lm = results.pose_landmarks.landmark\n",
    "        left_score  = arm_score(lm, \"LEFT\", mp_pose)\n",
    "        right_score = arm_score(lm, \"RIGHT\", mp_pose)\n",
    "        best_score  = max(left_score, right_score)\n",
    "\n",
    "        true_labels.append(cls)\n",
    "        pred_labels.append(score_to_label(best_score))\n",
    "\n",
    "pose.close()\n",
    "\n",
    "# ---------- è©•ä¼° ----------\n",
    "print(\"\\nğŸ“Š æ··æ·†çŸ©é™£ (é †åº p1~p5):\")\n",
    "cm = confusion_matrix(true_labels, pred_labels, labels=POSE_CLASSES)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nğŸ“ˆ åˆ†é¡å ±å‘Š:\")\n",
    "print(classification_report(true_labels, pred_labels,\n",
    "                            labels=POSE_CLASSES, digits=3))\n",
    "\n",
    "# ---------- è¼¸å‡ºåµæ¸¬å¤±æ•—æ¸…å–® ----------\n",
    "all_failed = read_failed_images + undetected_images\n",
    "if all_failed:\n",
    "    txt_path = Path(\"undetected_images.txt\")\n",
    "    with txt_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(all_failed))\n",
    "    print(f\"\\nâš ï¸  å…± {len(all_failed)} å¼µåœ–ç‰‡æœªç´å…¥è©•ä¼°ï¼Œæ¸…å–®å·²å¯«å…¥ {txt_path}\")\n",
    "    if read_failed_images:\n",
    "        print(f\"  - cv2 è®€å–å¤±æ•—ï¼š{len(read_failed_images)} å¼µ\")\n",
    "    if undetected_images:\n",
    "        print(f\"  - Pose æœªåµæ¸¬åˆ°äººé«”ï¼š{len(undetected_images)} å¼µ\")\n",
    "else:\n",
    "    print(\"\\nâœ… æ‰€æœ‰åœ–ç‰‡çš†æˆåŠŸåµæ¸¬ä¸¦ç´å…¥è©•ä¼°\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
